{
  "models": {
    "llm7b": {
      "name": "LLM-7B",
      "memory_gb": 14,
      "gpus_required": 1,
      "load_time_seconds": 10,
      "tokens_per_second": 50,
      "token_mean": 512,
      "token_std": 128,
      "inference_time_mean": 10.0,
      "inference_time_std": 2.0
    },
    "llm13b": {
      "name": "LLM-13B", 
      "memory_gb": 26,
      "gpus_required": 1,
      "load_time_seconds": 20,
      "tokens_per_second": 30,
      "token_mean": 768,
      "token_std": 192,
      "inference_time_mean": 15.0,
      "inference_time_std": 3.0
    }
  },
  "workflows": {
    "workflow1": {
      "name": "Simple LLM-7B",
      "nodes": [
        {
          "id": "node1",
          "model": "llm7b",
          "inputs": ["user_prompt"],
          "outputs": ["response"]
        }
      ],
      "edges": []
    },
    "workflow2": {
      "name": "Simple LLM-13B",
      "nodes": [
        {
          "id": "node1", 
          "model": "llm13b",
          "inputs": ["user_prompt"],
          "outputs": ["response"]
        }
      ],
      "edges": []
    }
  }
}